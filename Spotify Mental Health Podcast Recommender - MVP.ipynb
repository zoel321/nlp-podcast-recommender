{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69aaa0be",
   "metadata": {},
   "source": [
    "## MVP Summary\n",
    "\n",
    "The goal for this project is to create a recommendation system that can recommend a similar podcast episode (either from the same podcast or not, depending on user preference), given podcast and episode descriptions from Spotify on podcasts related to mental health. \n",
    "\n",
    "After cleaning/preprocessing the data, I tried a few vectorizer and topic model combinations. Using the Count Vectorizer with NMF seemed to yield the most interpretable topics (some still unidentified) along with top terms:\n",
    "\n",
    "#### Topic  1: \n",
    "life, u, people, talk, get, way, share, time, love, make\n",
    "\n",
    "#### Spiritual:\n",
    "Tarot, Soul, Lindsay, healing, u, card, Tribe, Wild, work, around\n",
    "\n",
    "#### Mental Health Support:\n",
    "health, mental, Health, Mental, Join, support, issue, conversation, people, experience\n",
    "\n",
    "#### Topic  4:\n",
    "wa, year, life, time, would, first, God, going, day, could\n",
    "\n",
    "#### Fitness/physical wellbeing:\n",
    "training, athlete, fitness, CrossFit, strength, coach, Barbell, program, get, Shrugged\n",
    "\n",
    "#### Older adults:\n",
    "Dr, older, adult, show, aging, expert, interview, find, January, care\n",
    "\n",
    "### Next Steps\n",
    "I will try out the SpaCy library to help with preprocessing proper nouns/names, as well as focus on some common compound terms, in order to improve the topics. Then I will perform topic modeling on Podcast descriptions, before using the final topic mdoels in my recommendation system. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987545cd",
   "metadata": {},
   "source": [
    "## Supplemental/Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c049aa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2a98652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ac029fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb0613d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1961d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF, TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26bf6d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "mh_podcasts = pd.read_pickle('mh_podcasts.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc99f462",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Podcast_Name</th>\n",
       "      <th>Ep_id</th>\n",
       "      <th>Ep_name</th>\n",
       "      <th>Ep_date</th>\n",
       "      <th>Ep_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(2020) Mental Health Explained | Created By Yo...</td>\n",
       "      <td>10JraOKEu4gb2dKQEwjhmm</td>\n",
       "      <td>Depression and Tics During Quarantine</td>\n",
       "      <td>2020-12-16</td>\n",
       "      <td>This episode helps explain the effects of quar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Being African American in 2021 and dealing wit...</td>\n",
       "      <td>4Vs1ajXhg5t53zHNDpM3wu</td>\n",
       "      <td>Chipping away at the mental health stigma</td>\n",
       "      <td>2021-10-11</td>\n",
       "      <td>The Black community has made enormous contribu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Being African American in 2021 and dealing wit...</td>\n",
       "      <td>6jFW6wq6Pafs0OLAlHVNRh</td>\n",
       "      <td>Being black in America in 2021</td>\n",
       "      <td>2021-10-08</td>\n",
       "      <td>With love for seven addressing mental health i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Being African American in 2021 and dealing wit...</td>\n",
       "      <td>4F5RugIvvmb8uI5fDqPmhz</td>\n",
       "      <td>Surviving a Narcissistic breakup : The Fear an...</td>\n",
       "      <td>2020-12-12</td>\n",
       "      <td>Moving on and healing from an narcissistic   -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Being African American in 2021 and dealing wit...</td>\n",
       "      <td>4eEe5dXg47re6BjpeyZdPx</td>\n",
       "      <td>Love and mental health 2020</td>\n",
       "      <td>2020-12-09</td>\n",
       "      <td>Love - relationship, mental health and parenti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Podcast_Name                   Ep_id  \\\n",
       "0  (2020) Mental Health Explained | Created By Yo...  10JraOKEu4gb2dKQEwjhmm   \n",
       "1  Being African American in 2021 and dealing wit...  4Vs1ajXhg5t53zHNDpM3wu   \n",
       "2  Being African American in 2021 and dealing wit...  6jFW6wq6Pafs0OLAlHVNRh   \n",
       "3  Being African American in 2021 and dealing wit...  4F5RugIvvmb8uI5fDqPmhz   \n",
       "4  Being African American in 2021 and dealing wit...  4eEe5dXg47re6BjpeyZdPx   \n",
       "\n",
       "                                             Ep_name     Ep_date  \\\n",
       "0            Depression and Tics During Quarantine    2020-12-16   \n",
       "1         Chipping away at the mental health stigma   2021-10-11   \n",
       "2                     Being black in America in 2021  2021-10-08   \n",
       "3  Surviving a Narcissistic breakup : The Fear an...  2020-12-12   \n",
       "4                        Love and mental health 2020  2020-12-09   \n",
       "\n",
       "                                             Ep_desc  \n",
       "0  This episode helps explain the effects of quar...  \n",
       "1  The Black community has made enormous contribu...  \n",
       "2  With love for seven addressing mental health i...  \n",
       "3  Moving on and healing from an narcissistic   -...  \n",
       "4  Love - relationship, mental health and parenti...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mh_podcasts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "487d8e3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20745 entries, 0 to 20744\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Podcast_Name  20745 non-null  object\n",
      " 1   Ep_id         20745 non-null  object\n",
      " 2   Ep_name       20745 non-null  object\n",
      " 3   Ep_date       20745 non-null  object\n",
      " 4   Ep_desc       20745 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 810.5+ KB\n"
     ]
    }
   ],
   "source": [
    "mh_podcasts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b19d7215",
   "metadata": {},
   "outputs": [],
   "source": [
    "podcast_names_df = pd.read_pickle('just_podcasts.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ce4d989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 350 entries, 0 to 349\n",
      "Data columns (total 3 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   Podcast_Name         350 non-null    object\n",
      " 1   Podcast_ShowID       350 non-null    object\n",
      " 2   Podcast_Description  350 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 8.3+ KB\n"
     ]
    }
   ],
   "source": [
    "podcast_names_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49c43099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Podcast_Name</th>\n",
       "      <th>Podcast_ShowID</th>\n",
       "      <th>Podcast_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(2020) Mental Health Explained | Created By Yo...</td>\n",
       "      <td>4pwPCZriBVbcLcufvtchsP</td>\n",
       "      <td>Hi, my name is Logan Isfeld, I am 17 years old...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Being African American in 2021 and dealing wit...</td>\n",
       "      <td>4eoXzwruqyu2yAh4jYA7EM</td>\n",
       "      <td>Being black in 2021 has its own challenges and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aubrey Marcus Podcast</td>\n",
       "      <td>0n7j2qseg6fu0Fj2dvzXVi</td>\n",
       "      <td>The Aubrey Marcus Podcast is an illuminating c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unfazed and Unbothered with Tasia and Camo</td>\n",
       "      <td>6MZJi1fkxSbqjfQiSqC5OL</td>\n",
       "      <td>Millions of eyes watching, the pressure, the n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barbell Shrugged</td>\n",
       "      <td>6MFeb0x9bw9wjrphztLSn9</td>\n",
       "      <td>Shrugged Collective is a network of fitness, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>Happy and Healthy Mind with Dr. Rozina</td>\n",
       "      <td>5XwuvVKnlVtKNBluBl0ITY</td>\n",
       "      <td>Hello and welcome to Happy and Healthy mind wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>NAH Podcast</td>\n",
       "      <td>0muSoy4HndaTpELvVDu1iW</td>\n",
       "      <td>Hey Hey! My name is Han or Hannah. Whichever y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>Healthcare Insight</td>\n",
       "      <td>5GO3DnQpENyNVJymwG8BjU</td>\n",
       "      <td>Ronald E. Bachman FSA, MAAA, CHC  President &amp; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>Mental Health Education in High Schools</td>\n",
       "      <td>2Ow2pcCGA3rcRDVxSjhI6C</td>\n",
       "      <td>Atkins et al. (2010). Toward the integration o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>Prabhat Ranjan Sarkar Discourses</td>\n",
       "      <td>3iV30kXhmDEJ5Ed1gEFVSm</td>\n",
       "      <td>My name is Mauricio Perez (Vimukta), I am a So...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Podcast_Name  \\\n",
       "0    (2020) Mental Health Explained | Created By Yo...   \n",
       "1    Being African American in 2021 and dealing wit...   \n",
       "2                                Aubrey Marcus Podcast   \n",
       "3           Unfazed and Unbothered with Tasia and Camo   \n",
       "4                                     Barbell Shrugged   \n",
       "..                                                 ...   \n",
       "345             Happy and Healthy Mind with Dr. Rozina   \n",
       "346                                        NAH Podcast   \n",
       "347                                 Healthcare Insight   \n",
       "348            Mental Health Education in High Schools   \n",
       "349                   Prabhat Ranjan Sarkar Discourses   \n",
       "\n",
       "             Podcast_ShowID                                Podcast_Description  \n",
       "0    4pwPCZriBVbcLcufvtchsP  Hi, my name is Logan Isfeld, I am 17 years old...  \n",
       "1    4eoXzwruqyu2yAh4jYA7EM  Being black in 2021 has its own challenges and...  \n",
       "2    0n7j2qseg6fu0Fj2dvzXVi  The Aubrey Marcus Podcast is an illuminating c...  \n",
       "3    6MZJi1fkxSbqjfQiSqC5OL  Millions of eyes watching, the pressure, the n...  \n",
       "4    6MFeb0x9bw9wjrphztLSn9  Shrugged Collective is a network of fitness, h...  \n",
       "..                      ...                                                ...  \n",
       "345  5XwuvVKnlVtKNBluBl0ITY  Hello and welcome to Happy and Healthy mind wi...  \n",
       "346  0muSoy4HndaTpELvVDu1iW  Hey Hey! My name is Han or Hannah. Whichever y...  \n",
       "347  5GO3DnQpENyNVJymwG8BjU  Ronald E. Bachman FSA, MAAA, CHC  President & ...  \n",
       "348  2Ow2pcCGA3rcRDVxSjhI6C  Atkins et al. (2010). Toward the integration o...  \n",
       "349  3iV30kXhmDEJ5Ed1gEFVSm  My name is Mauricio Perez (Vimukta), I am a So...  \n",
       "\n",
       "[350 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "podcast_names_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3566784d",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bb215f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def clean_regex(series):\n",
    "    # remove digits\n",
    "    desc = series.apply(lambda x: re.sub('\\d', '', x ))\n",
    "    # remove \\xa0 from string in Python: https://stackoverflow.com/questions/10993612/how-to-remove-xa0-from-string-in-python\n",
    "    desc = desc.apply(lambda x: x.replace(u'\\xa0', u''))\n",
    "    #remove the | and > symbols\n",
    "    desc = desc.apply(lambda x: re.sub('\\|.+', '', x))\n",
    "    desc = desc.apply(lambda x: re.sub('\\>.+', '', x))\n",
    "    #remove punctuation\n",
    "    desc = desc.apply(lambda x: re.sub('[%s]'% re.escape(string.punctuation), '', x))\n",
    "    #remove websites and info that comes after (seems like sponsorship)\n",
    "    desc = desc.apply(lambda x: re.sub('http.+', '', x))\n",
    "    desc = desc.apply(lambda x: re.sub('www.+', '', x))\n",
    "    #add in space before capital letters if none (some are combined together): referred https://stackoverflow.com/questions/199059/a-pythonic-way-to-insert-a-space-before-capital-letters)\n",
    "    desc = desc.apply(lambda x: re.sub(\"([A-Z])(?![A-Z])\", r\"\\1\", x))\n",
    "    return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26dab839",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = clean_regex(mh_podcasts.Ep_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb05f3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to lowercase words that are not identified as proper nouns, so can use stemmer/lemmatizer\n",
    "def lowercase(single_desc):\n",
    "    tokens = pos_tag(word_tokenize(single_desc))\n",
    "    edited_words = []\n",
    "    for item in tokens:\n",
    "        if (item[1] != 'NNP') and (item[1] != 'NNPS'):\n",
    "            edited_words.append(item[0].lower())\n",
    "        else:\n",
    "            edited_words.append(item[0])\n",
    "    return edited_words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81cbfed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_lower = cleaned.map(lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28609043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [this, episode, helps, explain, the, effects, ...\n",
       "1        [the, Black, community, has, made, enormous, c...\n",
       "2        [with, love, for, seven, addressing, mental, h...\n",
       "3        [moving, on, and, healing, from, an, narcissis...\n",
       "4        [Love, relationship, mental, health, and, pare...\n",
       "                               ...                        \n",
       "20740    [by, PR, Sarkar, founder, of, Ananda, MargaDis...\n",
       "20741    [by, PR, Sarkar, founder, of, Ananda, MargaDis...\n",
       "20742    [by, PR, Sarkar, founder, of, Ananda, MargaPub...\n",
       "20743    [Discourse, given, by, Prabhat, Ranjan, Sarkar...\n",
       "20744    [Discourse, given, by, Prabhat, Ranjan, Sarkar...\n",
       "Name: Ep_desc, Length: 20745, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee1d11f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efc89462",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "pstemmer = PorterStemmer()\n",
    "lstemmer = LancasterStemmer()\n",
    "sstemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5510433c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alan\n",
      "alan\n",
      "al\n",
      "alan\n",
      "Stern\n",
      "stern\n",
      "stern\n",
      "stern\n",
      "is\n",
      "is\n",
      "is\n",
      "is\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "planetary\n",
      "planetari\n",
      "planet\n",
      "planetari\n",
      "scientist\n",
      "scientist\n",
      "sci\n",
      "scientist\n",
      "and\n",
      "and\n",
      "and\n",
      "and\n",
      "astronautic\n",
      "astronaut\n",
      "astronaut\n",
      "astronaut\n",
      "engineer\n",
      "engin\n",
      "engin\n",
      "engin\n",
      "Alan\n",
      "alan\n",
      "al\n",
      "alan\n",
      "is\n",
      "is\n",
      "is\n",
      "is\n",
      "the\n",
      "the\n",
      "the\n",
      "the\n",
      "chief\n",
      "chief\n",
      "chief\n",
      "chief\n",
      "Exploration\n",
      "explor\n",
      "expl\n",
      "explor\n",
      "Officer\n",
      "offic\n",
      "off\n",
      "offic\n",
      "of\n",
      "of\n",
      "of\n",
      "of\n",
      "World\n",
      "world\n",
      "world\n",
      "world\n",
      "View\n",
      "view\n",
      "view\n",
      "view\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "company\n",
      "compani\n",
      "company\n",
      "compani\n",
      "that\n",
      "that\n",
      "that\n",
      "that\n",
      "is\n",
      "is\n",
      "is\n",
      "is\n",
      "pioneering\n",
      "pioneer\n",
      "pion\n",
      "pioneer\n",
      "the\n",
      "the\n",
      "the\n",
      "the\n",
      "stratocraft\n",
      "stratocraft\n",
      "stratocraft\n",
      "stratocraft\n",
      "industry\n",
      "industri\n",
      "industry\n",
      "industri\n",
      "Their\n",
      "their\n",
      "their\n",
      "their\n",
      "mission\n",
      "mission\n",
      "miss\n",
      "mission\n",
      "is\n",
      "is\n",
      "is\n",
      "is\n",
      "to\n",
      "to\n",
      "to\n",
      "to\n",
      "allow\n",
      "allow\n",
      "allow\n",
      "allow\n",
      "people\n",
      "peopl\n",
      "peopl\n",
      "peopl\n",
      "an\n",
      "an\n",
      "an\n",
      "an\n",
      "unparalleled\n",
      "unparallel\n",
      "unparallel\n",
      "unparallel\n",
      "experience\n",
      "experi\n",
      "expery\n",
      "experi\n",
      "from\n",
      "from\n",
      "from\n",
      "from\n",
      "the\n",
      "the\n",
      "the\n",
      "the\n",
      "edge\n",
      "edg\n",
      "edg\n",
      "edg\n",
      "of\n",
      "of\n",
      "of\n",
      "of\n",
      "space\n",
      "space\n",
      "spac\n",
      "space\n",
      "using\n",
      "use\n",
      "us\n",
      "use\n",
      "breakthrough\n",
      "breakthrough\n",
      "breakthrough\n",
      "breakthrough\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "helium\n",
      "helium\n",
      "hel\n",
      "helium\n",
      "ballooning\n",
      "balloon\n",
      "balloon\n",
      "balloon\n",
      "technology\n",
      "technolog\n",
      "technolog\n",
      "technolog\n",
      "Imagine\n",
      "imagin\n",
      "imagin\n",
      "imagin\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "luxurious\n",
      "luxuri\n",
      "luxury\n",
      "luxuri\n",
      "hour\n",
      "hour\n",
      "hour\n",
      "hour\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "viewing\n",
      "view\n",
      "view\n",
      "view\n",
      "capsule\n",
      "capsul\n",
      "caps\n",
      "capsul\n",
      "looking\n",
      "look\n",
      "look\n",
      "look\n",
      "down\n",
      "down\n",
      "down\n",
      "down\n",
      "at\n",
      "at\n",
      "at\n",
      "at\n",
      "the\n",
      "the\n",
      "the\n",
      "the\n",
      "great\n",
      "great\n",
      "gre\n",
      "great\n",
      "wonder\n",
      "wonder\n",
      "wond\n",
      "wonder\n",
      "of\n",
      "of\n",
      "of\n",
      "of\n",
      "our\n",
      "our\n",
      "our\n",
      "our\n",
      "world\n",
      "world\n",
      "world\n",
      "world\n",
      "and\n",
      "and\n",
      "and\n",
      "and\n",
      "up\n",
      "up\n",
      "up\n",
      "up\n",
      "to\n",
      "to\n",
      "to\n",
      "to\n",
      "the\n",
      "the\n",
      "the\n",
      "the\n",
      "heaven\n",
      "heaven\n",
      "heav\n",
      "heaven\n",
      "with\n",
      "with\n",
      "with\n",
      "with\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "view\n",
      "view\n",
      "view\n",
      "view\n",
      "almost\n",
      "almost\n",
      "almost\n",
      "almost\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "human\n",
      "human\n",
      "hum\n",
      "human\n",
      "have\n",
      "have\n",
      "hav\n",
      "have\n",
      "ever\n",
      "ever\n",
      "ev\n",
      "ever\n",
      "seen\n",
      "seen\n",
      "seen\n",
      "seen\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "am\n",
      "am\n",
      "am\n",
      "am\n",
      "so\n",
      "so\n",
      "so\n",
      "so\n",
      "excited\n",
      "excit\n",
      "excit\n",
      "excit\n",
      "to\n",
      "to\n",
      "to\n",
      "to\n",
      "be\n",
      "be\n",
      "be\n",
      "be\n",
      "involved\n",
      "involv\n",
      "involv\n",
      "involv\n",
      "with\n",
      "with\n",
      "with\n",
      "with\n",
      "World\n",
      "world\n",
      "world\n",
      "world\n",
      "View\n",
      "view\n",
      "view\n",
      "view\n",
      "and\n",
      "and\n",
      "and\n",
      "and\n",
      "for\n",
      "for\n",
      "for\n",
      "for\n",
      "this\n",
      "thi\n",
      "thi\n",
      "this\n",
      "project\n",
      "project\n",
      "project\n",
      "project\n",
      "to\n",
      "to\n",
      "to\n",
      "to\n",
      "come\n",
      "come\n",
      "com\n",
      "come\n",
      "to\n",
      "to\n",
      "to\n",
      "to\n",
      "fruition\n",
      "fruition\n",
      "fruit\n",
      "fruition\n",
      "on\n",
      "on\n",
      "on\n",
      "on\n",
      "this\n",
      "thi\n",
      "thi\n",
      "this\n",
      "podcast\n",
      "podcast\n",
      "podcast\n",
      "podcast\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "get\n",
      "get\n",
      "get\n",
      "get\n",
      "into\n",
      "into\n",
      "into\n",
      "into\n",
      "Alan\n",
      "alan\n",
      "al\n",
      "alan\n",
      "’\n",
      "’\n",
      "’\n",
      "’\n",
      "s\n",
      "s\n",
      "s\n",
      "s\n",
      "journey\n",
      "journey\n",
      "journey\n",
      "journey\n",
      "of\n",
      "of\n",
      "of\n",
      "of\n",
      "becoming\n",
      "becom\n",
      "becom\n",
      "becom\n",
      "an\n",
      "an\n",
      "an\n",
      "an\n",
      "astronaut\n",
      "astronaut\n",
      "astronaut\n",
      "astronaut\n",
      "flat\n",
      "flat\n",
      "flat\n",
      "flat\n",
      "earth\n",
      "earth\n",
      "ear\n",
      "earth\n",
      "moon\n",
      "moon\n",
      "moon\n",
      "moon\n",
      "landing\n",
      "land\n",
      "land\n",
      "land\n",
      "alien\n",
      "alien\n",
      "aly\n",
      "alien\n",
      "and\n",
      "and\n",
      "and\n",
      "and\n",
      "the\n",
      "the\n",
      "the\n",
      "the\n",
      "purview\n",
      "purview\n",
      "purview\n",
      "purview\n",
      "of\n",
      "of\n",
      "of\n",
      "of\n",
      "earth\n",
      "earth\n",
      "ear\n",
      "earth\n",
      "from\n",
      "from\n",
      "from\n",
      "from\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "higher\n",
      "higher\n",
      "high\n",
      "higher\n",
      "perspective\n",
      "perspect\n",
      "perspect\n",
      "perspect\n",
      "for\n",
      "for\n",
      "for\n",
      "for\n",
      "more\n",
      "more\n",
      "mor\n",
      "more\n",
      "information\n",
      "inform\n",
      "inform\n",
      "inform\n",
      "on\n",
      "on\n",
      "on\n",
      "on\n",
      "how\n",
      "how\n",
      "how\n",
      "how\n",
      "to\n",
      "to\n",
      "to\n",
      "to\n",
      "book\n",
      "book\n",
      "book\n",
      "book\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "reservation\n",
      "reserv\n",
      "reserv\n",
      "reserv\n",
      "check\n",
      "check\n",
      "check\n",
      "check\n",
      "out\n",
      "out\n",
      "out\n",
      "out\n"
     ]
    }
   ],
   "source": [
    "#comparing\n",
    "for word in cleaned_lower[23]:\n",
    "    lemmed = lemmatizer.lemmatize(word)\n",
    "    pstemmed = pstemmer.stem(word)\n",
    "    lstemmed = lstemmer.stem(word)\n",
    "    sstemmed = sstemmer.stem(word)\n",
    "    print(lemmed)\n",
    "    print(pstemmed)\n",
    "    print(lstemmed)\n",
    "    print(sstemmed)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9d46b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a list of words (each item in our 'cleaned' list), lemmatize each word \n",
    "def lem(words):\n",
    "    new_list = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return new_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb3316b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#will go with lemmatizer first (more conservative approach)\n",
    "cleaned_ll = cleaned_lower.map(lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bbf7024",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [this, episode, help, explain, the, effect, of...\n",
       "1        [the, Black, community, ha, made, enormous, co...\n",
       "2        [with, love, for, seven, addressing, mental, h...\n",
       "3        [moving, on, and, healing, from, an, narcissis...\n",
       "4        [Love, relationship, mental, health, and, pare...\n",
       "                               ...                        \n",
       "20740    [by, PR, Sarkar, founder, of, Ananda, MargaDis...\n",
       "20741    [by, PR, Sarkar, founder, of, Ananda, MargaDis...\n",
       "20742    [by, PR, Sarkar, founder, of, Ananda, MargaPub...\n",
       "20743    [Discourse, given, by, Prabhat, Ranjan, Sarkar...\n",
       "20744    [Discourse, given, by, Prabhat, Ranjan, Sarkar...\n",
       "Name: Ep_desc, Length: 20745, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "333ef2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import stopwords\n",
    "default_stop = stopwords.words('english')\n",
    "custom_stop = [\"Twitter\", \"Instagram\", \"follow\", \"Youtube\", \"Spotify\", \"check\", 'help', 'ha', 'episode', 'thing', \"YouTube\", \"podcasting\", \"like\", \"one\", \"podcast\", \"also\"]\n",
    "#my full list of stop words\n",
    "full_list = default_stop + custom_stop "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3a11fd",
   "metadata": {},
   "source": [
    "# Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91081718",
   "metadata": {},
   "source": [
    "Trying CV and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19906389",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = cleaned_ll.apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b542e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words=full_list, min_df=2, max_df=0.7, lowercase=False, token_pattern=r'(?u)\\b[A-Za-z]+\\b', max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9066476f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term = cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6adf2353",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AA</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABOUT</th>\n",
       "      <th>ACL</th>\n",
       "      <th>ADD</th>\n",
       "      <th>ADDebrief</th>\n",
       "      <th>ADHD</th>\n",
       "      <th>AI</th>\n",
       "      <th>AIDS</th>\n",
       "      <th>...</th>\n",
       "      <th>youre</th>\n",
       "      <th>youseason</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>youtubeleHOQHrNs</th>\n",
       "      <th>youve</th>\n",
       "      <th>yr</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20740</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20741</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20742</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20743</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20744</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20745 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       A  AA  ABC  ABOUT  ACL  ADD  ADDebrief  ADHD  AI  AIDS  ...  youre  \\\n",
       "0      0   0    0      0    0    0          0     0   0     0  ...      0   \n",
       "1      0   0    0      0    0    0          0     0   0     0  ...      0   \n",
       "2      0   0    0      0    0    0          0     0   0     0  ...      0   \n",
       "3      0   0    0      0    0    0          0     0   0     0  ...      0   \n",
       "4      0   0    0      0    0    0          0     0   0     0  ...      0   \n",
       "...   ..  ..  ...    ...  ...  ...        ...   ...  ..   ...  ...    ...   \n",
       "20740  0   0    0      0    0    0          0     0   0     0  ...      0   \n",
       "20741  0   0    0      0    0    0          0     0   0     0  ...      0   \n",
       "20742  1   0    0      0    0    0          0     0   0     0  ...      0   \n",
       "20743  2   0    0      0    0    0          0     0   0     0  ...      0   \n",
       "20744  0   0    0      0    0    0          0     0   0     0  ...      0   \n",
       "\n",
       "       youseason  youth  youtube  youtubeleHOQHrNs  youve  yr  zero  zone  \\\n",
       "0              0      0        0                 0      0   0     0     0   \n",
       "1              0      0        0                 0      0   0     0     0   \n",
       "2              0      0        0                 0      0   0     0     0   \n",
       "3              0      0        0                 0      0   0     0     0   \n",
       "4              0      0        0                 0      0   0     0     0   \n",
       "...          ...    ...      ...               ...    ...  ..   ...   ...   \n",
       "20740          0      0        0                 0      0   0     0     0   \n",
       "20741          0      0        0                 0      0   0     0     0   \n",
       "20742          0      0        0                 0      0   0     0     0   \n",
       "20743          0      0        0                 0      0   0     0     0   \n",
       "20744          0      0        0                 0      0   0     0     0   \n",
       "\n",
       "       zoom  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "...     ...  \n",
       "20740     0  \n",
       "20741     0  \n",
       "20742     0  \n",
       "20743     0  \n",
       "20744     0  \n",
       "\n",
       "[20745 rows x 10000 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm = pd.DataFrame(doc_term.toarray(), columns = cv.get_feature_names_out())\n",
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f264322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words_dict = {k: v for k, v in sorted(cv.vocabulary_.items(), key=lambda x: x[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba5965b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'zoom': 9999,\n",
       " 'zone': 9998,\n",
       " 'zero': 9997,\n",
       " 'yr': 9996,\n",
       " 'youve': 9995,\n",
       " 'youtubeleHOQHrNs': 9994,\n",
       " 'youtube': 9993,\n",
       " 'youth': 9992,\n",
       " 'youseason': 9991,\n",
       " 'youre': 9990,\n",
       " 'youngest': 9989,\n",
       " 'younger': 9988,\n",
       " 'young': 9987,\n",
       " 'youll': 9986,\n",
       " 'youin': 9985,\n",
       " 'youhow': 9984,\n",
       " 'youd': 9983,\n",
       " 'youarenottobusypodcast': 9982,\n",
       " 'yogi': 9981,\n",
       " 'yoga': 9980,\n",
       " 'yet': 9979,\n",
       " 'yesterday': 9978,\n",
       " 'yes': 9977,\n",
       " 'yep': 9976,\n",
       " 'yelling': 9975,\n",
       " 'yearold': 9974,\n",
       " 'year': 9973,\n",
       " 'yeah': 9972,\n",
       " 'yang': 9971,\n",
       " 'yall': 9970,\n",
       " 'ya': 9969,\n",
       " 'xx': 9968,\n",
       " 'xoxochristinechen': 9967,\n",
       " 'xoxo': 9966,\n",
       " 'xmo': 9965,\n",
       " 'x': 9964,\n",
       " 'wurrang': 9963,\n",
       " 'wrote': 9962,\n",
       " 'wrong': 9961,\n",
       " 'written': 9960,\n",
       " 'writing': 9959,\n",
       " 'writes': 9958,\n",
       " 'writer': 9957,\n",
       " 'write': 9956,\n",
       " 'wrist': 9955,\n",
       " 'wrestling': 9954,\n",
       " 'wrestler': 9953,\n",
       " 'wrestled': 9952,\n",
       " 'wrapping': 9951,\n",
       " 'wrapped': 9950,\n",
       " 'wrap': 9949,\n",
       " 'wow': 9948,\n",
       " 'woven': 9947,\n",
       " 'wounded': 9946,\n",
       " 'wound': 9945,\n",
       " 'wouldnt': 9944,\n",
       " 'would': 9943,\n",
       " 'worthy': 9942,\n",
       " 'worth': 9941,\n",
       " 'worst': 9940,\n",
       " 'worship': 9939,\n",
       " 'worse': 9938,\n",
       " 'worrying': 9937,\n",
       " 'worry': 9936,\n",
       " 'worried': 9935,\n",
       " 'worn': 9934,\n",
       " 'worm': 9933,\n",
       " 'worldwide': 9932,\n",
       " 'worldrenowned': 9931,\n",
       " 'worldclass': 9930,\n",
       " 'world': 9929,\n",
       " 'workshopsbe': 9928,\n",
       " 'workshop': 9927,\n",
       " 'workplace': 9926,\n",
       " 'workout': 9925,\n",
       " 'workload': 9924,\n",
       " 'worklife': 9923,\n",
       " 'working': 9922,\n",
       " 'workforce': 9921,\n",
       " 'worker': 9920,\n",
       " 'worked': 9919,\n",
       " 'workday': 9918,\n",
       " 'workbook': 9917,\n",
       " 'work': 9916,\n",
       " 'word': 9915,\n",
       " 'wood': 9914,\n",
       " 'wont': 9913,\n",
       " 'wondering': 9912,\n",
       " 'wonderful': 9911,\n",
       " 'wondered': 9910,\n",
       " 'wonder': 9909,\n",
       " 'womxn': 9908,\n",
       " 'womenowned': 9907,\n",
       " 'woman': 9906,\n",
       " 'woke': 9905,\n",
       " 'wizard': 9904,\n",
       " 'witty': 9903,\n",
       " 'witnessing': 9902,\n",
       " 'witnessed': 9901,\n",
       " 'witness': 9900,\n",
       " 'without': 9899,\n",
       " 'within': 9898,\n",
       " 'witch': 9897,\n",
       " 'wit': 9896,\n",
       " 'wishing': 9895,\n",
       " 'wish': 9894,\n",
       " 'wisely': 9893,\n",
       " 'wise': 9892,\n",
       " 'wisdom': 9891,\n",
       " 'wired': 9890,\n",
       " 'winter': 9889,\n",
       " 'winning': 9888,\n",
       " 'winner': 9887,\n",
       " 'wine': 9886,\n",
       " 'window': 9885,\n",
       " 'wind': 9884,\n",
       " 'win': 9883,\n",
       " 'willpower': 9882,\n",
       " 'willingness': 9881,\n",
       " 'willingly': 9880,\n",
       " 'willing': 9879,\n",
       " 'wildly': 9878,\n",
       " 'wilderness': 9877,\n",
       " 'wild': 9876,\n",
       " 'wife': 9875,\n",
       " 'widow': 9874,\n",
       " 'wider': 9873,\n",
       " 'widely': 9872,\n",
       " 'wide': 9871,\n",
       " 'wicked': 9870,\n",
       " 'whove': 9869,\n",
       " 'whose': 9868,\n",
       " 'wholesome': 9867,\n",
       " 'wholeness': 9866,\n",
       " 'whole': 9865,\n",
       " 'white': 9864,\n",
       " 'whilst': 9863,\n",
       " 'whether': 9862,\n",
       " 'wherever': 9861,\n",
       " 'whenever': 9860,\n",
       " 'wheelchair': 9859,\n",
       " 'wheel': 9858,\n",
       " 'whats': 9857,\n",
       " 'whatever': 9856,\n",
       " 'wewillgetthroughthisorg': 9855,\n",
       " 'weve': 9854,\n",
       " 'western': 9853,\n",
       " 'werent': 9852,\n",
       " 'went': 9851,\n",
       " 'wellrounded': 9850,\n",
       " 'wellness': 9849,\n",
       " 'wellknown': 9848,\n",
       " 'wellbeing': 9847,\n",
       " 'well': 9846,\n",
       " 'welcoming': 9845,\n",
       " 'welcome': 9844,\n",
       " 'weird': 9843,\n",
       " 'weightlifting': 9842,\n",
       " 'weightlifter': 9841,\n",
       " 'weighted': 9840,\n",
       " 'weight': 9839,\n",
       " 'weigh': 9838,\n",
       " 'weekly': 9837,\n",
       " 'weekend': 9836,\n",
       " 'week': 9835,\n",
       " 'weed': 9834,\n",
       " 'wedding': 9833,\n",
       " 'wed': 9832,\n",
       " 'websiteseason': 9831,\n",
       " 'websiteemail': 9830,\n",
       " 'website': 9829,\n",
       " 'webinar': 9828,\n",
       " 'webchat': 9827,\n",
       " 'web': 9826,\n",
       " 'weaving': 9825,\n",
       " 'weave': 9824,\n",
       " 'weather': 9823,\n",
       " 'wearing': 9822,\n",
       " 'wear': 9821,\n",
       " 'weapon': 9820,\n",
       " 'wealth': 9819,\n",
       " 'weakness': 9818,\n",
       " 'weak': 9817,\n",
       " 'wayshower': 9816,\n",
       " 'way': 9815,\n",
       " 'wave': 9814,\n",
       " 'water': 9813,\n",
       " 'watching': 9812,\n",
       " 'watched': 9811,\n",
       " 'watch': 9810,\n",
       " 'wasting': 9809,\n",
       " 'wasted': 9808,\n",
       " 'waste': 9807,\n",
       " 'wasnt': 9806,\n",
       " 'wash': 9805,\n",
       " 'warrior': 9804,\n",
       " 'warranty': 9803,\n",
       " 'warning': 9802,\n",
       " 'warm': 9801,\n",
       " 'warfare': 9800,\n",
       " 'wardrobe': 9799,\n",
       " 'ward': 9798,\n",
       " 'war': 9797,\n",
       " 'wanting': 9796,\n",
       " 'wanted': 9795,\n",
       " 'want': 9794,\n",
       " 'wan': 9793,\n",
       " 'wall': 9792,\n",
       " 'walking': 9791,\n",
       " 'walked': 9790,\n",
       " 'walk': 9789,\n",
       " 'waking': 9788,\n",
       " 'wake': 9787,\n",
       " 'waiting': 9786,\n",
       " 'wait': 9785,\n",
       " 'wagon': 9784,\n",
       " 'wage': 9783,\n",
       " 'wa': 9782,\n",
       " 'w': 9781,\n",
       " 'vulnerable': 9780,\n",
       " 'vulnerability': 9779,\n",
       " 'vow': 9778,\n",
       " 'voting': 9777,\n",
       " 'voted': 9776,\n",
       " 'vote': 9775,\n",
       " 'von': 9774,\n",
       " 'volunteering': 9773,\n",
       " 'volunteer': 9772,\n",
       " 'volume': 9771,\n",
       " 'volleyball': 9770,\n",
       " 'void': 9769,\n",
       " 'voiced': 9768,\n",
       " 'voice': 9767,\n",
       " 'vocal': 9766,\n",
       " 'vocabulary': 9765,\n",
       " 'vitamin': 9764,\n",
       " 'vitality': 9763,\n",
       " 'vital': 9762,\n",
       " 'visualize': 9761,\n",
       " 'visualization': 9760,\n",
       " 'visual': 9759,\n",
       " 'visiting': 9758,\n",
       " 'visited': 9757,\n",
       " 'visit': 9756,\n",
       " 'visionary': 9755,\n",
       " 'vision': 9754,\n",
       " 'visible': 9753,\n",
       " 'visibility': 9752,\n",
       " 'virus': 9751,\n",
       " 'virtue': 9750,\n",
       " 'virtually': 9749,\n",
       " 'virtual': 9748,\n",
       " 'viral': 9747,\n",
       " 'violent': 9746,\n",
       " 'violence': 9745,\n",
       " 'village': 9744,\n",
       " 'viewpoint': 9743,\n",
       " 'viewing': 9742,\n",
       " 'viewer': 9741,\n",
       " 'viewed': 9740,\n",
       " 'view': 9739,\n",
       " 'video': 9738,\n",
       " 'victory': 9737,\n",
       " 'victorian': 9736,\n",
       " 'victim': 9735,\n",
       " 'vice': 9734,\n",
       " 'vibration': 9733,\n",
       " 'vibrant': 9732,\n",
       " 'vibe': 9731,\n",
       " 'via': 9730,\n",
       " 'veteran': 9729,\n",
       " 'vet': 9728,\n",
       " 'vessel': 9727,\n",
       " 'versus': 9726,\n",
       " 'version': 9725,\n",
       " 'verse': 9724,\n",
       " 'verbal': 9723,\n",
       " 'venue': 9722,\n",
       " 'venture': 9721,\n",
       " 'vent': 9720,\n",
       " 'veil': 9719,\n",
       " 'vehicle': 9718,\n",
       " 'vegetarian': 9717,\n",
       " 'vegetable': 9716,\n",
       " 'veganism': 9715,\n",
       " 'vegan': 9714,\n",
       " 'vault': 9713,\n",
       " 'vast': 9712,\n",
       " 'varying': 9711,\n",
       " 'various': 9710,\n",
       " 'variety': 9709,\n",
       " 'varied': 9708,\n",
       " 'variation': 9707,\n",
       " 'variable': 9706,\n",
       " 'variability': 9705,\n",
       " 'van': 9704,\n",
       " 'valued': 9703,\n",
       " 'value': 9702,\n",
       " 'valuable': 9701,\n",
       " 'validation': 9700,\n",
       " 'validated': 9699,\n",
       " 'validate': 9698,\n",
       " 'valid': 9697,\n",
       " 'vagina': 9696,\n",
       " 'vaccine': 9695,\n",
       " 'vaccination': 9694,\n",
       " 'vacation': 9693,\n",
       " 'v': 9692,\n",
       " 'utilizing': 9691,\n",
       " 'utilizes': 9690,\n",
       " 'utilized': 9689,\n",
       " 'utilize': 9688,\n",
       " 'utilization': 9687,\n",
       " 'usually': 9686,\n",
       " 'usual': 9685,\n",
       " 'using': 9684,\n",
       " 'usethat': 9683,\n",
       " 'user': 9682,\n",
       " 'useful': 9681,\n",
       " 'used': 9680,\n",
       " 'use': 9679,\n",
       " 'usage': 9678,\n",
       " 'us': 9677,\n",
       " 'urgency': 9676,\n",
       " 'urge': 9675,\n",
       " 'urban': 9674,\n",
       " 'uptodate': 9673,\n",
       " 'upside': 9672,\n",
       " 'upset': 9671,\n",
       " 'ups': 9670,\n",
       " 'upper': 9669,\n",
       " 'upon': 9668,\n",
       " 'upload': 9667,\n",
       " 'uplifting': 9666,\n",
       " 'uplift': 9665,\n",
       " 'upgrade': 9664,\n",
       " 'updated': 9663,\n",
       " 'update': 9662,\n",
       " 'upcoming': 9661,\n",
       " 'upbringing': 9660,\n",
       " 'upbeat': 9659,\n",
       " 'unwanted': 9658,\n",
       " 'unusual': 9657,\n",
       " 'untreated': 9656,\n",
       " 'unto': 9655,\n",
       " 'unsure': 9654,\n",
       " 'unstuck': 9653,\n",
       " 'unseen': 9652,\n",
       " 'unsafe': 9651,\n",
       " 'unrealistic': 9650,\n",
       " 'unprecedented': 9649,\n",
       " 'unpleasant': 9648,\n",
       " 'unparalleled': 9647,\n",
       " 'unpacks': 9646,\n",
       " 'unpacking': 9645,\n",
       " 'unpack': 9644,\n",
       " 'unnecessary': 9643,\n",
       " 'unlock': 9642,\n",
       " 'unlikely': 9641,\n",
       " 'unlike': 9640,\n",
       " 'unless': 9639,\n",
       " 'unleash': 9638,\n",
       " 'unlearn': 9637,\n",
       " 'unknown': 9636,\n",
       " 'university': 9635,\n",
       " 'universe': 9634,\n",
       " 'universal': 9633,\n",
       " 'unity': 9632,\n",
       " 'uniting': 9631,\n",
       " 'unit': 9630,\n",
       " 'uniquely': 9629,\n",
       " 'unique': 9628,\n",
       " 'union': 9627,\n",
       " 'unhelpful': 9626,\n",
       " 'unhealthy': 9625,\n",
       " 'unhappy': 9624,\n",
       " 'unfortunately': 9623,\n",
       " 'unfortunate': 9622,\n",
       " 'unfold': 9621,\n",
       " 'unfiltered': 9620,\n",
       " 'unfamiliar': 9619,\n",
       " 'unexpectedly': 9618,\n",
       " 'unexpected': 9617,\n",
       " 'unedited': 9616,\n",
       " 'undiagnosed': 9615,\n",
       " 'understood': 9614,\n",
       " 'understatement': 9613,\n",
       " 'understands': 9612,\n",
       " 'understanding': 9611,\n",
       " 'understand': 9610,\n",
       " 'underneath': 9609,\n",
       " 'underlying': 9608,\n",
       " 'undergraduate': 9607,\n",
       " 'undergoing': 9606,\n",
       " 'underestimate': 9605,\n",
       " 'uncovering': 9604,\n",
       " 'uncovered': 9603,\n",
       " 'uncover': 9602,\n",
       " 'unconventional': 9601,\n",
       " 'unconscious': 9600,\n",
       " 'unconditionally': 9599,\n",
       " 'unconditional': 9598,\n",
       " 'uncomfortable': 9597,\n",
       " 'uncertainty': 9596,\n",
       " 'uncertain': 9595,\n",
       " 'uncensored': 9594,\n",
       " 'unceded': 9593,\n",
       " 'unbelievable': 9592,\n",
       " 'unaware': 9591,\n",
       " 'unapologetically': 9590,\n",
       " 'unable': 9589,\n",
       " 'ultramarathon': 9588,\n",
       " 'ultra': 9587,\n",
       " 'ultimately': 9586,\n",
       " 'ultimate': 9585,\n",
       " 'ugly': 9584,\n",
       " 'u': 9583,\n",
       " 'tyranny': 9582,\n",
       " 'typically': 9581,\n",
       " 'typical': 9580,\n",
       " 'type': 9579,\n",
       " 'twotime': 9578,\n",
       " 'twopart': 9577,\n",
       " 'two': 9576,\n",
       " 'twittercommentalpodcast': 9575,\n",
       " 'twitter': 9574,\n",
       " 'twisted': 9573,\n",
       " 'twist': 9572,\n",
       " 'twin': 9571,\n",
       " 'twice': 9570,\n",
       " 'twentyfive': 9569,\n",
       " 'twenty': 9568,\n",
       " 'twelve': 9567,\n",
       " 'tweet': 9566,\n",
       " 'tweak': 9565,\n",
       " 'tv': 9564,\n",
       " 'tutorial': 9563,\n",
       " 'turning': 9562,\n",
       " 'turned': 9561,\n",
       " 'turn': 9560,\n",
       " 'turmoil': 9559,\n",
       " 'tunnel': 9558,\n",
       " 'tuning': 9557,\n",
       " 'tuned': 9556,\n",
       " 'tune': 9555,\n",
       " 'tumor': 9554,\n",
       " 'trying': 9553,\n",
       " 'try': 9552,\n",
       " 'truth': 9551,\n",
       " 'trusting': 9550,\n",
       " 'trusted': 9549,\n",
       " 'trust': 9548,\n",
       " 'truly': 9547,\n",
       " 'true': 9546,\n",
       " 'truck': 9545,\n",
       " 'troubled': 9544,\n",
       " 'trouble': 9543,\n",
       " 'troop': 9542,\n",
       " 'triumph': 9541,\n",
       " 'trip': 9540,\n",
       " 'trio': 9539,\n",
       " 'triggeringto': 9538,\n",
       " 'triggering': 9537,\n",
       " 'triggered': 9536,\n",
       " 'trigger': 9535,\n",
       " 'tried': 9534,\n",
       " 'tricky': 9533,\n",
       " 'trick': 9532,\n",
       " 'tribute': 9531,\n",
       " 'tribulation': 9530,\n",
       " 'tribe': 9529,\n",
       " 'triathlon': 9528,\n",
       " 'triathlete': 9527,\n",
       " 'trial': 9526,\n",
       " 'trend': 9525,\n",
       " 'tremendous': 9524,\n",
       " 'tree': 9523,\n",
       " 'treatment': 9522,\n",
       " 'treating': 9521,\n",
       " 'treated': 9520,\n",
       " 'treat': 9519,\n",
       " 'treasure': 9518,\n",
       " 'travelling': 9517,\n",
       " 'traveling': 9516,\n",
       " 'traveler': 9515,\n",
       " 'traveled': 9514,\n",
       " 'travel': 9513,\n",
       " 'traumatic': 9512,\n",
       " 'trauma': 9511,\n",
       " 'trapped': 9510,\n",
       " 'trap': 9509,\n",
       " 'transplant': 9508,\n",
       " 'transparent': 9507,\n",
       " 'transparency': 9506,\n",
       " 'transmission': 9505,\n",
       " 'translates': 9504,\n",
       " 'translated': 9503,\n",
       " 'translate': 9502,\n",
       " 'transitioning': 9501,\n",
       " 'transitioned': 9500,\n",
       " 'transition': 9499,\n",
       " 'transgender': 9498,\n",
       " 'transforms': 9497,\n",
       " 'transforming': 9496,\n",
       " 'transformed': 9495,\n",
       " 'transformative': 9494,\n",
       " 'transformational': 9493,\n",
       " 'transformation': 9492,\n",
       " 'transform': 9491,\n",
       " 'transfer': 9490,\n",
       " 'transcription': 9489,\n",
       " 'transcript': 9488,\n",
       " 'transcend': 9487,\n",
       " 'trans': 9486,\n",
       " 'trajectory': 9485,\n",
       " 'trait': 9484,\n",
       " 'training': 9483,\n",
       " 'trainer': 9482,\n",
       " 'trained': 9481,\n",
       " 'train': 9480,\n",
       " 'trailer': 9479,\n",
       " 'trail': 9478,\n",
       " 'tragic': 9477,\n",
       " 'tragedy': 9476,\n",
       " 'traffic': 9475,\n",
       " 'traditionally': 9474,\n",
       " 'traditional': 9473,\n",
       " 'tradition': 9472,\n",
       " 'traded': 9471,\n",
       " 'trade': 9470,\n",
       " 'tracking': 9469,\n",
       " 'track': 9468,\n",
       " 'trace': 9467,\n",
       " 'toy': 9466,\n",
       " 'toxicity': 9465,\n",
       " 'toxic': 9464,\n",
       " 'town': 9463,\n",
       " 'towards': 9462,\n",
       " 'toward': 9461,\n",
       " 'touring': 9460,\n",
       " 'tour': 9459,\n",
       " 'toughness': 9458,\n",
       " 'toughest': 9457,\n",
       " 'tough': 9456,\n",
       " 'touchmary': 9455,\n",
       " 'touching': 9454,\n",
       " 'touched': 9453,\n",
       " 'touch': 9452,\n",
       " 'totally': 9451,\n",
       " 'total': 9450,\n",
       " 'tosubscribe': 9449,\n",
       " 'toselfmastery': 9448,\n",
       " 'topical': 9447,\n",
       " 'topic': 9446,\n",
       " 'top': 9445,\n",
       " 'toonnitcomaubrey': 9444,\n",
       " 'toolkit': 9443,\n",
       " 'toolbox': 9442,\n",
       " 'tool': 9441,\n",
       " 'took': 9440,\n",
       " 'tonight': 9439,\n",
       " 'tone': 9438,\n",
       " 'ton': 9437,\n",
       " 'tomorrow': 9436,\n",
       " 'toll': 9435,\n",
       " 'tolerance': 9434,\n",
       " 'told': 9433,\n",
       " 'toilet': 9432,\n",
       " 'together': 9431,\n",
       " 'toemail': 9430,\n",
       " 'toe': 9429,\n",
       " 'todo': 9428,\n",
       " 'todiscover': 9427,\n",
       " 'toddler': 9426,\n",
       " 'todaywellevatrcomwellevatr': 9425,\n",
       " 'today': 9424,\n",
       " 'titled': 9423,\n",
       " 'title': 9422,\n",
       " 'tissue': 9421,\n",
       " 'tired': 9420,\n",
       " 'tip': 9419,\n",
       " 'tiny': 9418,\n",
       " 'timing': 9417,\n",
       " 'timely': 9416,\n",
       " 'timeline': 9415,\n",
       " 'timeless': 9414,\n",
       " 'time': 9413,\n",
       " 'till': 9412,\n",
       " 'tiktok': 9411,\n",
       " 'tight': 9410,\n",
       " 'tiffany': 9409,\n",
       " 'tier': 9408,\n",
       " 'tied': 9407,\n",
       " 'tie': 9406,\n",
       " 'ticket': 9405,\n",
       " 'thyroid': 9404,\n",
       " 'thus': 9403,\n",
       " 'thrust': 9402,\n",
       " 'thrown': 9401,\n",
       " 'throwing': 9400,\n",
       " 'throwback': 9399,\n",
       " 'throw': 9398,\n",
       " 'throughout': 9397,\n",
       " 'thriving': 9396,\n",
       " 'thrives': 9395,\n",
       " 'thrive': 9394,\n",
       " 'thrilled': 9393,\n",
       " 'threshold': 9392,\n",
       " 'threetime': 9391,\n",
       " 'three': 9390,\n",
       " 'threatening': 9389,\n",
       " 'threatened': 9388,\n",
       " 'threat': 9387,\n",
       " 'thread': 9386,\n",
       " 'thousand': 9385,\n",
       " 'thoughtprovoking': 9384,\n",
       " 'thoughtful': 9383,\n",
       " 'thought': 9382,\n",
       " 'though': 9381,\n",
       " 'thisisyoursgmailcom': 9380,\n",
       " 'thisisyours': 9379,\n",
       " 'thirty': 9378,\n",
       " 'thirddegreepodcastnhgmailcom': 9377,\n",
       " 'third': 9376,\n",
       " 'thinkingoutloudmailcom': 9375,\n",
       " 'thinking': 9374,\n",
       " 'thinker': 9373,\n",
       " 'think': 9372,\n",
       " 'thin': 9371,\n",
       " 'thigh': 9370,\n",
       " 'thief': 9369,\n",
       " 'thick': 9368,\n",
       " 'theyve': 9367,\n",
       " 'theyre': 9366,\n",
       " 'thesandiegoscout': 9365,\n",
       " 'therefore': 9364,\n",
       " 'therapy': 9363,\n",
       " 'therapist': 9362,\n",
       " 'therapeutic': 9361,\n",
       " 'theperfectlyimperfectpodcastgmailcom': 9360,\n",
       " 'theory': 9359,\n",
       " 'theorigin': 9358,\n",
       " 'theology': 9357,\n",
       " 'themusclemaven': 9356,\n",
       " 'thementallyillmentorgmailcom': 9355,\n",
       " 'theme': 9354,\n",
       " 'theladylikechatter': 9353,\n",
       " 'theketofitcom': 9352,\n",
       " 'thehistoryofmedicinepodcastgmailcomsay': 9351,\n",
       " 'thefacebook': 9350,\n",
       " 'thedaily': 9349,\n",
       " 'theburnoutisrealpod': 9348,\n",
       " 'theblackpodcastclub': 9347,\n",
       " 'thebeautypodcastgmailcom': 9346,\n",
       " 'theatre': 9345,\n",
       " 'theater': 9344,\n",
       " 'thealbrechtauthorsfb': 9343,\n",
       " 'thealbrechtauthors': 9342,\n",
       " 'thats': 9341,\n",
       " 'thanksgiving': 9340,\n",
       " 'thanks': 9339,\n",
       " 'thankful': 9338,\n",
       " 'thank': 9337,\n",
       " 'th': 9336,\n",
       " 'textbook': 9335,\n",
       " 'text': 9334,\n",
       " 'testosterone': 9333,\n",
       " 'testing': 9332,\n",
       " 'testimony': 9331,\n",
       " 'tested': 9330,\n",
       " 'test': 9329,\n",
       " 'terror': 9328,\n",
       " 'territory': 9327,\n",
       " 'terrifying': 9326,\n",
       " 'terrible': 9325,\n",
       " 'term': 9324,\n",
       " 'tenure': 9323,\n",
       " 'tension': 9322,\n",
       " 'tennis': 9321,\n",
       " 'tends': 9320,\n",
       " 'tending': 9319,\n",
       " 'tender': 9318,\n",
       " 'tendency': 9317,\n",
       " 'tend': 9316,\n",
       " 'ten': 9315,\n",
       " 'temptation': 9314,\n",
       " 'temporary': 9313,\n",
       " 'tempo': 9312,\n",
       " 'temple': 9311,\n",
       " 'temperature': 9310,\n",
       " 'telling': 9309,\n",
       " 'tell': 9308,\n",
       " 'television': 9307,\n",
       " 'telehealth': 9306,\n",
       " 'teeth': 9305,\n",
       " 'teenager': 9304,\n",
       " 'teenage': 9303,\n",
       " 'teen': 9302,\n",
       " 'technology': 9301,\n",
       " 'technique': 9300,\n",
       " 'technical': 9299,\n",
       " 'tech': 9298,\n",
       " 'tear': 9297,\n",
       " 'teammate': 9296,\n",
       " 'team': 9295,\n",
       " 'teaching': 9294,\n",
       " 'teacher': 9293,\n",
       " 'teach': 9292,\n",
       " 'tea': 9291,\n",
       " 'tbhpod': 9290,\n",
       " 'tax': 9289,\n",
       " 'taught': 9288,\n",
       " 'tattoo': 9287,\n",
       " 'taste': 9286,\n",
       " 'task': 9285,\n",
       " 'tarot': 9284,\n",
       " 'targeted': 9283,\n",
       " 'target': 9282,\n",
       " 'tapping': 9281,\n",
       " 'tapped': 9280,\n",
       " 'tap': 9279,\n",
       " 'tangible': 9278,\n",
       " 'tangent': 9277,\n",
       " 'tamarakanderson': 9276,\n",
       " 'tall': 9275,\n",
       " 'talking': 9274,\n",
       " 'talked': 9273,\n",
       " 'talk': 9272,\n",
       " 'talented': 9271,\n",
       " 'talent': 9270,\n",
       " 'tale': 9269,\n",
       " 'taking': 9268,\n",
       " 'taken': 9267,\n",
       " 'takeawaysconnect': 9266,\n",
       " 'takeaway': 9265,\n",
       " 'take': 9264,\n",
       " 'tail': 9263,\n",
       " 'tag': 9262,\n",
       " 'tactical': 9261,\n",
       " 'tactic': 9260,\n",
       " 'tackling': 9259,\n",
       " 'tackle': 9258,\n",
       " 'taboo': 9257,\n",
       " 'table': 9256,\n",
       " 'ta': 9255,\n",
       " 'systemic': 9254,\n",
       " 'system': 9253,\n",
       " 'syndrome': 9252,\n",
       " 'symptom': 9251,\n",
       " 'symbol': 9250,\n",
       " 'sword': 9249,\n",
       " 'switching': 9248,\n",
       " 'switch': 9247,\n",
       " 'swing': 9246,\n",
       " 'swimming': 9245,\n",
       " 'swimmer': 9244,\n",
       " 'swim': 9243,\n",
       " 'sweet': 9242,\n",
       " 'sweat': 9241,\n",
       " 'swearing': 9240,\n",
       " 'swear': 9239,\n",
       " 'swap': 9238,\n",
       " 'sustained': 9237,\n",
       " 'sustainable': 9236,\n",
       " 'sustainability': 9235,\n",
       " 'sustain': 9234,\n",
       " 'suspect': 9233,\n",
       " 'survivor': 9232,\n",
       " 'surviving': 9231,\n",
       " 'survived': 9230,\n",
       " 'survive': 9229,\n",
       " 'survival': 9228,\n",
       " 'survey': 9227,\n",
       " 'surrounding': 9226,\n",
       " 'surrounded': 9225,\n",
       " 'surround': 9224,\n",
       " 'surrendering': 9223,\n",
       " 'surrender': 9222,\n",
       " 'surprisingly': 9221,\n",
       " 'surprising': 9220,\n",
       " 'surprised': 9219,\n",
       " 'surprise': 9218,\n",
       " 'surgical': 9217,\n",
       " 'surgery': 9216,\n",
       " 'surgeon': 9215,\n",
       " 'surfing': 9214,\n",
       " 'surfer': 9213,\n",
       " 'surface': 9212,\n",
       " 'surf': 9211,\n",
       " 'surely': 9210,\n",
       " 'sure': 9209,\n",
       " 'supremacy': 9208,\n",
       " 'suppress': 9207,\n",
       " 'supposed': 9206,\n",
       " 'supportive': 9205,\n",
       " 'supporting': 9204,\n",
       " 'supporter': 9203,\n",
       " 'supported': 9202,\n",
       " 'support': 9201,\n",
       " 'supply': 9200,\n",
       " 'supplier': 9199,\n",
       " 'supplementation': 9198,\n",
       " 'supplement': 9197,\n",
       " 'supervisor': 9196,\n",
       " 'superstar': 9195,\n",
       " 'superpower': 9194,\n",
       " 'supernatural': 9193,\n",
       " 'superior': 9192,\n",
       " 'superhero': 9191,\n",
       " 'superfoods': 9190,\n",
       " 'superfood': 9189,\n",
       " 'super': 9188,\n",
       " 'sunshine': 9187,\n",
       " 'sun': 9186,\n",
       " 'summit': 9185,\n",
       " 'summer': 9184,\n",
       " 'summary': 9183,\n",
       " 'sum': 9182,\n",
       " 'suitable': 9181,\n",
       " 'suit': 9180,\n",
       " 'suicide': 9179,\n",
       " 'suicidal': 9178,\n",
       " 'suggests': 9177,\n",
       " 'suggestion': 9176,\n",
       " 'suggested': 9175,\n",
       " 'suggest': 9174,\n",
       " 'sugar': 9173,\n",
       " 'suffering': 9172,\n",
       " 'sufferer': 9171,\n",
       " 'suffered': 9170,\n",
       " 'suffer': 9169,\n",
       " 'suddenly': 9168,\n",
       " 'sudden': 9167,\n",
       " 'sucking': 9166,\n",
       " 'suck': 9165,\n",
       " 'successfully': 9164,\n",
       " 'successful': 9163,\n",
       " 'success': 9162,\n",
       " 'succeed': 9161,\n",
       " 'subtle': 9160,\n",
       " 'substitute': 9159,\n",
       " 'substance': 9158,\n",
       " 'subsequently': 9157,\n",
       " 'subsequent': 9156,\n",
       " 'subscription': 9155,\n",
       " 'subscribing': 9154,\n",
       " 'subscriber': 9153,\n",
       " 'subscribe': 9152,\n",
       " 'submitted': 9151,\n",
       " 'submission': 9150,\n",
       " 'subjective': 9149,\n",
       " 'subject': 9148,\n",
       " 'subconscious': 9147,\n",
       " 'style': 9146,\n",
       " 'stupid': 9145,\n",
       " 'stuff': 9144,\n",
       " 'studying': 9143,\n",
       " 'study': 9142,\n",
       " 'studio': 9141,\n",
       " 'studied': 9140,\n",
       " 'student': 9139,\n",
       " 'stuck': 9138,\n",
       " 'struggling': 9137,\n",
       " 'struggled': 9136,\n",
       " 'struggle': 9135,\n",
       " 'structured': 9134,\n",
       " 'structure': 9133,\n",
       " 'struck': 9132,\n",
       " 'strongman': 9131,\n",
       " 'strongly': 9130,\n",
       " 'strongest': 9129,\n",
       " 'stronger': 9128,\n",
       " 'strong': 9127,\n",
       " 'stroke': 9126,\n",
       " 'striving': 9125,\n",
       " 'strives': 9124,\n",
       " 'strive': 9123,\n",
       " 'strip': 9122,\n",
       " 'striking': 9121,\n",
       " 'strike': 9120,\n",
       " 'stride': 9119,\n",
       " 'strict': 9118,\n",
       " 'stretching': 9117,\n",
       " 'stretch': 9116,\n",
       " 'stressor': 9115,\n",
       " 'stressing': 9114,\n",
       " 'stressful': 9113,\n",
       " 'stressed': 9112,\n",
       " 'stress': 9111,\n",
       " 'strengthening': 9110,\n",
       " 'strengthen': 9109,\n",
       " 'strength': 9108,\n",
       " 'street': 9107,\n",
       " 'streaming': 9106,\n",
       " 'stream': 9105,\n",
       " 'strategy': 9104,\n",
       " 'strategist': 9103,\n",
       " 'strategieschange': 9102,\n",
       " 'strategically': 9101,\n",
       " 'strategic': 9100,\n",
       " 'stranger': 9099,\n",
       " 'strange': 9098,\n",
       " 'strain': 9097,\n",
       " 'straight': 9096,\n",
       " 'stphorm': 9095,\n",
       " 'storytelling': 9094,\n",
       " 'storyteller': 9093,\n",
       " 'story': 9092,\n",
       " 'storm': 9091,\n",
       " 'storiesofhopeinhardtimes': 9090,\n",
       " 'store': 9089,\n",
       " 'stopping': 9088,\n",
       " 'stopped': 9087,\n",
       " 'stop': 9086,\n",
       " 'stood': 9085,\n",
       " 'stone': 9084,\n",
       " 'stomach': 9083,\n",
       " 'stoic': 9082,\n",
       " 'stock': 9081,\n",
       " 'stir': 9080,\n",
       " 'stint': 9079,\n",
       " 'stimulus': 9078,\n",
       " 'stimulation': 9077,\n",
       " 'stillness': 9076,\n",
       " 'still': 9075,\n",
       " 'stigma': 9074,\n",
       " 'sticking': 9073,\n",
       " 'stick': 9072,\n",
       " 'steroid': 9071,\n",
       " 'stereotype': 9070,\n",
       " 'stepping': 9069,\n",
       " 'stepped': 9068,\n",
       " 'stepbystep': 9067,\n",
       " 'step': 9066,\n",
       " 'stem': 9065,\n",
       " 'steer': 9064,\n",
       " 'steel': 9063,\n",
       " 'stealing': 9062,\n",
       " 'steal': 9061,\n",
       " 'steady': 9060,\n",
       " 'staying': 9059,\n",
       " 'stayhome': 9058,\n",
       " 'stayed': 9057,\n",
       " 'stay': 9056,\n",
       " 'status': 9055,\n",
       " 'stats': 9054,\n",
       " 'statistic': 9053,\n",
       " 'station': 9052,\n",
       " 'statement': 9051,\n",
       " 'stated': 9050,\n",
       " 'state': 9049,\n",
       " 'startup': 9048,\n",
       " 'starting': 9047,\n",
       " 'started': 9046,\n",
       " 'start': 9045,\n",
       " 'starred': 9044,\n",
       " 'star': 9043,\n",
       " 'standup': 9042,\n",
       " 'standing': 9041,\n",
       " 'standard': 9040,\n",
       " 'stand': 9039,\n",
       " 'stance': 9038,\n",
       " 'stalking': 9037,\n",
       " 'stake': 9036,\n",
       " 'stage': 9035,\n",
       " 'staff': 9034,\n",
       " 'stack': 9033,\n",
       " 'stable': 9032,\n",
       " 'stability': 9031,\n",
       " 'st': 9030,\n",
       " 'squatting': 9029,\n",
       " 'squat': 9028,\n",
       " 'square': 9027,\n",
       " 'squad': 9026,\n",
       " 'sprint': 9025,\n",
       " 'spring': 9024,\n",
       " 'spreading': 9023,\n",
       " 'spread': 9022,\n",
       " 'spouse': 9021,\n",
       " 'spotlight': 9020,\n",
       " 'spotify': 9019,\n",
       " 'spot': 9018,\n",
       " 'sporting': 9017,\n",
       " 'sport': 9016,\n",
       " 'spooky': 9015,\n",
       " 'spontaneously': 9014,\n",
       " 'spontaneous': 9013,\n",
       " 'sponsoring': 9012,\n",
       " 'sponsored': 9011,\n",
       " 'sponsor': 9010,\n",
       " 'spoken': 9009,\n",
       " 'spoke': 9008,\n",
       " 'spoiler': 9007,\n",
       " 'split': 9006,\n",
       " 'spite': 9005,\n",
       " 'spit': 9004,\n",
       " 'spiritually': 9003,\n",
       " 'spirituality': 9002,\n",
       " 'spiritual': 9001,\n",
       " 'spirit': 9000,\n",
       " ...}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c63134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF\n",
    "tfidf_vec = TfidfVectorizer(stop_words=full_list, min_df=2, max_df=0.7, lowercase=False, token_pattern=r'(?u)\\b[A-Za-z]+\\b', max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6f8c9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_tfidf = tfidf_vec.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2755155",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AA</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABOUT</th>\n",
       "      <th>ACL</th>\n",
       "      <th>ADD</th>\n",
       "      <th>ADDebrief</th>\n",
       "      <th>ADHD</th>\n",
       "      <th>AI</th>\n",
       "      <th>AIDS</th>\n",
       "      <th>...</th>\n",
       "      <th>youre</th>\n",
       "      <th>youseason</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>youtubeleHOQHrNs</th>\n",
       "      <th>youve</th>\n",
       "      <th>yr</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20740</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20741</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20742</th>\n",
       "      <td>0.124303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20743</th>\n",
       "      <td>0.141641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20744</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20745 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              A   AA  ABC  ABOUT  ACL  ADD  ADDebrief  ADHD   AI  AIDS  ...  \\\n",
       "0      0.000000  0.0  0.0    0.0  0.0  0.0        0.0   0.0  0.0   0.0  ...   \n",
       "1      0.000000  0.0  0.0    0.0  0.0  0.0        0.0   0.0  0.0   0.0  ...   \n",
       "2      0.000000  0.0  0.0    0.0  0.0  0.0        0.0   0.0  0.0   0.0  ...   \n",
       "3      0.000000  0.0  0.0    0.0  0.0  0.0        0.0   0.0  0.0   0.0  ...   \n",
       "4      0.000000  0.0  0.0    0.0  0.0  0.0        0.0   0.0  0.0   0.0  ...   \n",
       "...         ...  ...  ...    ...  ...  ...        ...   ...  ...   ...  ...   \n",
       "20740  0.000000  0.0  0.0    0.0  0.0  0.0        0.0   0.0  0.0   0.0  ...   \n",
       "20741  0.000000  0.0  0.0    0.0  0.0  0.0        0.0   0.0  0.0   0.0  ...   \n",
       "20742  0.124303  0.0  0.0    0.0  0.0  0.0        0.0   0.0  0.0   0.0  ...   \n",
       "20743  0.141641  0.0  0.0    0.0  0.0  0.0        0.0   0.0  0.0   0.0  ...   \n",
       "20744  0.000000  0.0  0.0    0.0  0.0  0.0        0.0   0.0  0.0   0.0  ...   \n",
       "\n",
       "       youre  youseason  youth  youtube  youtubeleHOQHrNs  youve   yr  zero  \\\n",
       "0        0.0        0.0    0.0      0.0               0.0    0.0  0.0   0.0   \n",
       "1        0.0        0.0    0.0      0.0               0.0    0.0  0.0   0.0   \n",
       "2        0.0        0.0    0.0      0.0               0.0    0.0  0.0   0.0   \n",
       "3        0.0        0.0    0.0      0.0               0.0    0.0  0.0   0.0   \n",
       "4        0.0        0.0    0.0      0.0               0.0    0.0  0.0   0.0   \n",
       "...      ...        ...    ...      ...               ...    ...  ...   ...   \n",
       "20740    0.0        0.0    0.0      0.0               0.0    0.0  0.0   0.0   \n",
       "20741    0.0        0.0    0.0      0.0               0.0    0.0  0.0   0.0   \n",
       "20742    0.0        0.0    0.0      0.0               0.0    0.0  0.0   0.0   \n",
       "20743    0.0        0.0    0.0      0.0               0.0    0.0  0.0   0.0   \n",
       "20744    0.0        0.0    0.0      0.0               0.0    0.0  0.0   0.0   \n",
       "\n",
       "       zone  zoom  \n",
       "0       0.0   0.0  \n",
       "1       0.0   0.0  \n",
       "2       0.0   0.0  \n",
       "3       0.0   0.0  \n",
       "4       0.0   0.0  \n",
       "...     ...   ...  \n",
       "20740   0.0   0.0  \n",
       "20741   0.0   0.0  \n",
       "20742   0.0   0.0  \n",
       "20743   0.0   0.0  \n",
       "20744   0.0   0.0  \n",
       "\n",
       "[20745 rows x 10000 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_tfidf = pd.DataFrame(doc_term_tfidf.toarray(), columns = tfidf_vec.get_feature_names_out())\n",
    "\n",
    "dtm_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6981aeb",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bd2401",
   "metadata": {},
   "source": [
    "Trying NMF first, using the vectorized data from CountVectorizer and TF-IDF Vectorizer (to compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "508936e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NMF \n",
    "nmf_act = NMF(6, init = 'nndsvda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f57f63b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = nmf_act.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08003acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display the top n terms in each topic- sourced from Metis\n",
    "def display_topics(model, feature_names, no_top_words, topic_names = None): \n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix + 1)\n",
    "        else:\n",
    "            print(\"\\nTopic: \", topic_names[ix])\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "    print(\"\\n\")\n",
    "    return model, feature_names, no_top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2fa60f03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  1\n",
      "life, u, people, talk, get, way, share, time, love, make\n",
      "\n",
      "Topic  2\n",
      "Tarot, Soul, Lindsay, healing, u, card, Tribe, Wild, work, around\n",
      "\n",
      "Topic  3\n",
      "health, mental, Health, Mental, Join, support, issue, conversation, people, experience\n",
      "\n",
      "Topic  4\n",
      "wa, year, life, time, would, first, God, going, day, could\n",
      "\n",
      "Topic  5\n",
      "training, athlete, fitness, CrossFit, strength, coach, Barbell, program, get, Shrugged\n",
      "\n",
      "Topic  6\n",
      "Dr, older, adult, show, aging, expert, interview, find, January, care\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# output contents for each topic - Count Vectorizer with NMF\n",
    "\n",
    "output = display_topics(nmf, cv.get_feature_names_out(), 10)\n",
    "output;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975cf4c9",
   "metadata": {},
   "source": [
    "Taking a look to preview episode descriptions associated with topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60b08263",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic = nmf.transform(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75112992",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic_df = pd.DataFrame(doc_topic.round(3), columns = [1,2,3,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ec002af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>0.057</td>\n",
       "      <td>1.258</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6432</th>\n",
       "      <td>0.038</td>\n",
       "      <td>1.191</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6434</th>\n",
       "      <td>0.015</td>\n",
       "      <td>1.188</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6436</th>\n",
       "      <td>0.029</td>\n",
       "      <td>1.242</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6439</th>\n",
       "      <td>0.033</td>\n",
       "      <td>1.244</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553</th>\n",
       "      <td>0.025</td>\n",
       "      <td>1.613</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6554</th>\n",
       "      <td>0.002</td>\n",
       "      <td>1.391</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6555</th>\n",
       "      <td>0.024</td>\n",
       "      <td>1.479</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6558</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.443</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6559</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.614</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1      2      3      4      5      6\n",
       "6431  0.057  1.258  0.013  0.036  0.036  0.000\n",
       "6432  0.038  1.191  0.013  0.016  0.000  0.000\n",
       "6434  0.015  1.188  0.011  0.092  0.000  0.000\n",
       "6436  0.029  1.242  0.007  0.016  0.008  0.000\n",
       "6439  0.033  1.244  0.007  0.005  0.000  0.000\n",
       "...     ...    ...    ...    ...    ...    ...\n",
       "6553  0.025  1.613  0.011  0.021  0.031  0.000\n",
       "6554  0.002  1.391  0.005  0.029  0.000  0.000\n",
       "6555  0.024  1.479  0.003  0.090  0.018  0.000\n",
       "6558  0.000  1.443  0.000  0.014  0.000  0.004\n",
       "6559  0.000  1.614  0.000  0.000  0.000  0.000\n",
       "\n",
       "[90 rows x 6 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_df[doc_topic_df[2] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ff7ff824",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_corpus = mh_podcasts.Ep_desc.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f3a3da25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Welcome to a new Weekly Medicine Minisode, Wild Souls! This week, we are working with Four of Cups and Queen of Cups.   With Four of Cups, we are being called to review and reflect, to honor the process of sacred digestion. We cannot pick up and truly drink from that fourth cup, making room for the new cycles and experiences of life, until we have fully integrated what has been. This is a gentle death process, a welcome release of something that we no longer need to carry.   With Queen of Cups, we are getting a lot of support on how to both hold this work AND the duties and responsibilities of our earthly day to day. How do we make space for our emotional digestion, our intuitive clearing, and our dishes, deadlines, kids, and creation time? By touching in with this archetype, we can begin to discover how this kind of both/and work is possible. _________  ABOUT THE PODCAST\\xa0 Tarot for the Wild Soul Podcast explores the cards through an inclusive, trauma informed perspective, rooted in compassion, common sense, and critical thinking.  Through a weaving of intuitively channeled downloads, answers to listener questions, and lessons around the cards, Tarot for the Wild Soul offers ways to view the Tarot as helpful, applicable medicine that can provide nourishment and clarity to us in our day to day lives.   ABOUT LINDSAY Lindsay Mack is a queer intuitive Tarot teacher, and the host of TFTWS podcast.  Lindsay is the creator of Soul Tarot, a reinterpretation and intentional utilization of the Tarot as a non-predictive healing tool, one that is can assist us in differentiating the noise of our mind from the truth of our soul.\\xa0Through her regularly sold out workshops, retreats and online Tarot courses, Lindsay has had the profound honor of teaching Soul Tarot to thousands of people from all around the world.  As a joyful and healthy survivor of childhood abuse,\\xa0trauma & PTSD, Lindsay is passionately dedicated to honoring and helping to bring space, light and healing to those who are experiencing mental, emotional or physical suffering. It was the healing from a breakdown in 2014 that fully birthed her into this sacred work and onto her soul path. It is an organic part of her healing work with the Tarot,\\xa0and she is honored to be sharing these offerings to those who feel called to them.  Honoring and acknowledging that this podcast is recorded on the unceded land of The Confederated Tribes of Grand Ronde, currently called Portland, OR, with the deepest respect to the Kalapuya Tribe, Cowlitz Tribe, and Atfalati Tribe.   WEBSITE: www.tarotforthewildsoul.com FOLLOW US ON IG at @wildsoulhealing  PODCAST EDITOR: Chase Voorhees PODCAST ART: Rachelle Sartini Garner'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep_corpus[6431]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd9b7bd",
   "metadata": {},
   "source": [
    "Continuing baseline topic modeling attempts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "561456d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nmf_tfidf = nmf_act.fit(dtm_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e8c999ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  1\n",
      "date, show, David, created, Kato, note, today, Video, Audio, join\n",
      "\n",
      "Topic  2\n",
      "life, u, talk, wa, way, time, get, people, make, share\n",
      "\n",
      "Topic  3\n",
      "FULL, EP, Abbie, guest, host, Nat, edge, FIRST, Jacob, w\n",
      "\n",
      "Topic  4\n",
      "Sanctuary, Buddhist, Meditation, guided, Awareness, open, HMR, Aggacitta, Mindful, Hokkien\n",
      "\n",
      "Topic  5\n",
      "Official, Site, Visit, ad, megaphonefmadchoices, choice, Learn, Joe, Camo, Follow\n",
      "\n",
      "Topic  6\n",
      "mental, health, Join, Health, Bobby, factor, Mental, delve, condition, Temps\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# output contents for each topic - TF-IDF Vectorizer with NMF\n",
    "output = display_topics(nmf_tfidf, tfidf_vec.get_feature_names_out(), 10)\n",
    "output;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51990687",
   "metadata": {},
   "source": [
    "Trying LDA now, using the vectorized data from CountVectorizer and TF-IDF Vectorizer (to compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "346249ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSA \n",
    "lsa_act = TruncatedSVD(n_components=4, n_iter=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "62e3bb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa = lsa_act.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c7f9a3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  1\n",
      "wa, life, u, health, people, time, mental, get, talk, year\n",
      "\n",
      "Topic  2\n",
      "Tarot, Soul, Lindsay, healing, card, u, Tribe, Wild, around, called\n",
      "\n",
      "Topic  3\n",
      "health, mental, Dr, older, Health, adult, Mental, show, care, aging\n",
      "\n",
      "Topic  4\n",
      "wa, mental, health, year, older, family, Health, adult, Tarot, Mental\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# output contents for each topic - Count Vectorizer with LSA\n",
    "\n",
    "output = display_topics(lsa, cv.get_feature_names_out(), 6)\n",
    "output;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5829d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_tfidf = lsa_act.fit(dtm_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "91641880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  1\n",
      "date, show, life, u, talk, health, mental, get, wa, share\n",
      "\n",
      "Topic  2\n",
      "life, u, health, mental, talk, wa, share, way, time, get\n",
      "\n",
      "Topic  3\n",
      "FULL, EP, Abbie, Nat, host, guest, edge, FIRST, Jacob, w\n",
      "\n",
      "Topic  4\n",
      "Sanctuary, Buddhist, Meditation, guided, Awareness, open, HMR, Aggacitta, Mindful, Hokkien\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# output contents for each topic - TF-IDF Vectorizer with LSA\n",
    "output = display_topics(lsa_tfidf, tfidf_vec.get_feature_names_out(), 10)\n",
    "output;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
